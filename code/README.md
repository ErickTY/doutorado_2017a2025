# AI Model Pipeline - README

Este repositÃ³rio contÃ©m uma classe Python que implementa um pipeline completo de prÃ©-processamento e treinamento de modelos de InteligÃªncia Artificial (IA), incluindo redes neurais, Ã¡rvores de decisÃ£o, modelos ensemble, e modelos avanÃ§ados como Extreme Learning Machine (ELM) e Echo State Network (ESN).

---

## ğŸ”§ Funcionalidades

### ğŸ“‰ PrÃ©-processamento:

| TÃ©cnica                  | MÃ©todo Aplicado                        | Objetivo |
|---------------------------|------------------------------------------|---------|
| **NormalizaÃ§Ã£o**          | `MinMaxScaler()`                         | Escala os dados para o intervalo [0,1] |
| **PCA**                   | `PCA(n_components=n)`                    | Reduz a dimensionalidade mantendo a maior variÃ¢ncia |
| **ImportÃ¢ncia de Features**| `RandomForestClassifier().feature_importances_` | Mede a relevÃ¢ncia de cada atributo |
| **ExtraÃ§Ã£o de Features** | `SelectKBest(score_func=f_classif, k=k)` | Seleciona as *k* melhores features com ANOVA F |

### ğŸ§  Modelos de IA:

| Modelo                  | MÃ©todo | DescriÃ§Ã£o |
|-------------------------|--------|-----------|
| **MLP (Rede Neural)**   | `train_mlp()` | Rede com camadas ocultas (classificaÃ§Ã£o geral) |
| **Ãrvore de DecisÃ£o (DT)** | `train_dt()` | Modelo baseado em regras if-then |
| **Random Forest (RF)**  | `train_rf()` | Conjunto de Ã¡rvores para melhorar performance |
| **RNA RAM**             | `train_ram()` | Simula rede baseada em RAM com baixa profundidade |
| **ELM**                 | `train_elm()` | Rede neural com camada Ãºnica e pesos aleatÃ³rios |
| **ESN**                 | `train_esn()` | Rede neural recorrente com reservatÃ³rio fixo |

---

## ğŸ” ObservaÃ§Ã£o sobre Feature Importance e Feature Extraction

### Feature Importance e Feature Extraction sÃ£o prÃ©-processamentos ou anÃ¡lise exploratÃ³ria?

#### ğŸ”¹ Feature Importance
- Ã‰ usada para medir a relevÃ¢ncia de variÃ¡veis para prediÃ§Ã£o.
- Pode ser:
  - **AnÃ¡lise exploratÃ³ria**: quando usada para interpretar e compreender os dados.
  - **PrÃ© ou pÃ³s-processamento**: quando os resultados sÃ£o usados para ajustar o modelo (ex: eliminar variÃ¡veis).

#### ğŸ”¹ Feature Extraction
- Cria novas variÃ¡veis a partir das existentes (ex: PCA).
- Ã‰ classificada como:
  - **PrÃ©-processamento**: altera os dados antes do treinamento do modelo.
  - Raramente Ã© considerada parte da anÃ¡lise exploratÃ³ria (exceto para visualizaÃ§Ã£o dimensional).

#### ğŸ“„ Resumo

| TÃ©cnica             | EDA? | PrÃ©-processamento? | PÃ³s-processamento? |
|---------------------|------|----------------------|--------------------|
| Feature Importance  | âœ…  | âœ…                   | âœ…                 |
| Feature Extraction  | âŒ  | âœ…                   | âŒ                 |

---

## ğŸ¯ Por que foi usado ANOVA F em vez de SHAP?

### ANOVA F (f_classif)
- Ã‰ um teste estatÃ­stico que mede a variÃ¢ncia entre grupos (classes) para cada feature.
- Avalia a relaÃ§Ã£o entre cada variÃ¡vel independente e a variÃ¡vel alvo.
- Muito eficiente, rÃ¡pido e funciona **antes do modelo ser treinado**.
- Ideal para seleÃ§Ã£o de atributos em estÃ¡gios iniciais.

### SHAP (SHapley Additive exPlanations)
- MÃ©todo baseado em teoria dos jogos para explicar o impacto de cada feature na prediÃ§Ã£o.
- Ã‰ **pÃ³s-modelo**: precisa de um modelo treinado para funcionar.
- Mais pesado computacionalmente, mas mais interpretÃ¡vel.
- Ideal para auditoria e interpretaÃ§Ã£o fina do comportamento do modelo.

### ğŸ“Œ Comparativo

| CritÃ©rio                  | ANOVA F                     | SHAP                                  |
|--------------------------|-----------------------------|----------------------------------------|
| Tipo                     | EstatÃ­stica univariada       | Explicabilidade baseada em modelo     |
| PrÃ©-requisito            | Nenhum modelo treinado       | Requer modelo jÃ¡ treinado             |
| Custo computacional      | Muito baixo                  | Alto                                   |
| Interpretabilidade       | MÃ©dia                        | Alta                                   |
| Quando usar?             | SeleÃ§Ã£o inicial de features  | Entender comportamento do modelo      |

### âœ… ConclusÃ£o
> ANOVA F foi utilizado neste projeto por ser leve, eficaz e ideal para a seleÃ§Ã£o inicial de variÃ¡veis, enquanto SHAP Ã© mais indicado para explicaÃ§Ã£o de modelos jÃ¡ treinados.

---
## âš–ï¸ Requisitos

```bash
pip install numpy pandas scikit-learn hpelm easyesn
```

Obs: Se nÃ£o for utilizar ELM ou ESN, pode remover `hpelm` e `easyesn`.

---

## ğŸ“š Como Usar

```python
from sklearn.datasets import load_iris
from ai_pipeline import AIModelPipeline

# Carregar dataset
data = load_iris()
X, y = data.data, data.target

# Criar pipeline
pipeline = AIModelPipeline(X, y)

# Etapas de prÃ©-processamento
pipeline.normalize()
pipeline.apply_pca(n_components=3)
pipeline.feature_importance()
pipeline.feature_extraction(k=3)

# Treinamento dos modelos
pipeline.train_mlp()
pipeline.train_dt()
pipeline.train_rf()
pipeline.train_elm()
pipeline.train_esn()
pipeline.train_ram()

# SumÃ¡rio de resultados
pipeline.summary()
```

---

## ğŸŒ Estrutura do Projeto

```
.
â”œâ”€â”€ ai_pipeline.py       # Classe principal com prÃ©-processamentos e modelos
â”œâ”€â”€ codigo_doutorado_tsfel_pycaret.ipynb  # Jupyter Notebook com o cÃ³digo principal
â”œâ”€â”€ README.md            # Este arquivo
```

---

## ğŸš€ Objetivo

Este projeto visa fornecer uma ferramenta simples e modular para experimentaÃ§Ã£o com diferentes tÃ©cnicas de prÃ©-processamento e modelos de IA, sendo Ãºtil para fins educacionais e prototipagem rÃ¡pida.

---

## âœ… LicenÃ§a

Este projeto Ã© de uso livre para fins acadÃªmicos e educacionais.

---

## ğŸš‘ Suporte

Para dÃºvidas, entre em contato via [Issues](https://github.com/seu-usuario/seu-repositorio/issues) ou envie um pull request!


